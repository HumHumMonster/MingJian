{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from itertools import product\n",
    "pd.set_option('display.max_info_columns', 500)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_row', 300)\n",
    "pd.set_option('display.float_format', lambda x: ' %.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data/1_预处理/train/\"\n",
    "test_dir = \"./data/1_预处理/A/\"\n",
    "\n",
    "特征_train_dir = \"./data/2_特征/train/\"\n",
    "特征_test_dir = \"./data/2_特征/A/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = {}\n",
    "df_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 df_train 和 df_test\n",
    "train_date_range = pd.date_range(\n",
    "    start='2014-01-01 00:00:00',\n",
    "    end='2019-12-31 23:00:00',  # 包含最后一日的23:00\n",
    "    freq='h'  # 每小时频率\n",
    ")\n",
    "test_date_range = pd.date_range(\n",
    "    start='2020-01-01 00:00:00',\n",
    "    end='2021-12-31 23:00:00',  # 包含最后一日的23:00\n",
    "    freq='h'  # 每小时频率\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_dir + '雨量水位' + \".pkl\" , \"rb\" ) as file :\n",
    "    df_train['雨量水位'] = pickle.load(file)\n",
    "with open(test_dir + '雨量水位' + \".pkl\" , \"rb\" ) as file :\n",
    "    df_test['雨量水位'] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、按照时间获取流量最大值、求和等数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_特征 = df_train['雨量水位'].groupby(\"时间\")['值'].agg(['max' , 'min' , 'sum' , 'std']).reset_index()\n",
    "df_test_特征 = df_test['雨量水位'].groupby(\"时间\")['值'].agg(['max' , 'min' , 'sum' , 'std']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(特征_train_dir + '基础特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_train_特征, file)\n",
    "with open(特征_test_dir + '基础特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_test_特征, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、对于共有的所有检测站点，都求0，1，3，6，12，24，36，48小时内的流量情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "共有监测站 = [i for i in df_train['雨量水位']['名称'].unique() if i in df_test['雨量水位']['名称'].unique()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义所有 (统计量, 窗口) 组合\n",
    "stats = ['max', 'min' , 'std' , 'sum' , 'mean' , 'skew']\n",
    "windows = ['3h' , '6h' , '12h' , '24h' , '36h' , '48h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前处理站点为: 万安镇雨量  当前处理站点为: 下保村雨量  当前处理站点为: 下墩村雨量  当前处理站点为: 下洋坂雨量  当前处理站点为: 下洋村雨量  当前处理站点为: 下路岭雨量  当前处理站点为: 东上村雨量  当前处理站点为: 东游镇雨量  当前处理站点为: 九丘雨量  当前处理站点为: 京口村雨量  当前处理站点为: 半山村雨量  当前处理站点为: 厚德村雨量  当前处理站点为: 双鲤村雨量  当前处理站点为: 台溪乡雨量  当前处理站点为: 后村雨量  当前处理站点为: 后洋雨量  当前处理站点为: 均中村雨量  当前处理站点为: 埔上镇雨量  当前处理站点为: 夏茂镇雨量  当前处理站点为: 夏阳乡雨量  当前处理站点为: 外洋村雨量  当前处理站点为: 大儒村雨量  当前处理站点为: 大华镇雨量  当前处理站点为: 大口窑雨量  当前处理站点为: 大横镇曲楼甲新农村雨量  当前处理站点为: 天心岛花园雨量  当前处理站点为: 安砂镇雨量  当前处理站点为: 官昌村雨量  当前处理站点为: 富屯溪流域面雨量  当前处理站点为: 小华村雨量  当前处理站点为: 小西门头社区雨量  当前处理站点为: 山下乡雨量  当前处理站点为: 山坊雨量  当前处理站点为: 岭坪雨量  当前处理站点为: 年坂山雨量  当前处理站点为: 广平镇雨量  当前处理站点为: 库区流域面雨量  当前处理站点为: 建溪流域面雨量  当前处理站点为: 文峰村雨量  当前处理站点为: 新桥头雨量  当前处理站点为: 新源村雨量  当前处理站点为: 新阳镇雨量  当前处理站点为: 景山新村雨量  当前处理站点为: 杉坜雨量  当前处理站点为: 李坊村雨量  当前处理站点为: 林后岗雨量  当前处理站点为: 柯坑村雨量  当前处理站点为: 桐木村雨量  当前处理站点为: 桥下村雨量  当前处理站点为: 桥南村雨量  当前处理站点为: 梅仙镇雨量  当前处理站点为: 梅园小区雨量  当前处理站点为: 梅山镇雨量  当前处理站点为: 梅树湾新村雨量  当前处理站点为: 梅溪村雨量  当前处理站点为: 梓溪村雨量  当前处理站点为: 槐南镇雨量  当前处理站点为: 樟树村雨量  当前处理站点为: 横坑村雨量  当前处理站点为: 横洋雨量  当前处理站点为: 民主村雨量  当前处理站点为: 水东区间流域面雨量  当前处理站点为: 水东坝上雨量  当前处理站点为: 水东面雨量  当前处理站点为: 水南村雨量  当前处理站点为: 水口坝上(左岸)雨量  当前处理站点为: 水口坝上雨量  当前处理站点为: 水口面雨量  当前处理站点为: 永坑村雨量  当前处理站点为: 池潭坝上雨量  当前处理站点为: 汤泉村雨量  当前处理站点为: 沙坝下雨量  当前处理站点为: 沙溪流域面雨量  当前处理站点为: 洽湖村雨量  当前处理站点为: 测试雨量  当前处理站点为: 漈村雨量  当前处理站点为: 白叶山雨量  当前处理站点为: 白源雨量  当前处理站点为: 石塔山雨量  当前处理站点为: 碗厂村雨量  当前处理站点为: 福源小区雨量  当前处理站点为: 福记雨量  当前处理站点为: 端溪村雨量  当前处理站点为: 绿柳村雨量  当前处理站点为: 联合镇雨量  当前处理站点为: 肖坂村雨量  当前处理站点为: 胡坊镇雨量  当前处理站点为: 芦坪雨量  当前处理站点为: 茶窠雨量  当前处理站点为: 莘口镇雨量  当前处理站点为: 街面面雨量  当前处理站点为: 西城镇雨量  当前处理站点为: 西津村雨量  当前处理站点为: 西燕村雨量  当前处理站点为: 西表村雨量  当前处理站点为: 观华园雨量  当前处理站点为: 车洋坂雨量  当前处理站点为: 里坪厂雨量  当前处理站点为: 里洋村雨量  当前处理站点为: 金岭村雨量  当前处理站点为: 雍口实时面雨量  当前处理站点为: 雍口面雨量  当前处理站点为: 雪峰新村雨量  当前处理站点为: 龙口村雨量  "
     ]
    }
   ],
   "source": [
    "df_特征_train = pd.DataFrame(train_date_range, columns=['时间'])\n",
    "df = df_train['雨量水位'].copy()\n",
    "df = df[df['名称'].isin(共有监测站)]\n",
    "for 站点名称, group in df.groupby('名称', group_keys=False) :\n",
    "    print(f\"当前处理站点为: {站点名称}\" , end='  ')  # 输出站点ID\n",
    "\n",
    "    # 按时间排序并设置索引\n",
    "    group = group.sort_values('时间').set_index('时间')\n",
    "    \n",
    "    # 用 product 生成所有组合\n",
    "    for stat, window in product(stats, windows):\n",
    "        group[f'{站点名称}_{stat}_{window}'] = group['值'].rolling(window, closed='both').agg(stat)\n",
    "    group = group.drop(columns=['名称', '站点id', '值', '平均值', '最大值', '最大值发生时间', '最小值', '最小值发生时间']).reset_index()\n",
    "    group = group.drop_duplicates(subset='时间', keep='first')\n",
    "    # print(group)\n",
    "    df_特征_train = df_特征_train.merge(group , on='时间' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前处理站点为: 万安镇雨量  当前处理站点为: 下保村雨量  当前处理站点为: 下墩村雨量  当前处理站点为: 下洋坂雨量  当前处理站点为: 下洋村雨量  当前处理站点为: 下路岭雨量  当前处理站点为: 东上村雨量  当前处理站点为: 东游镇雨量  当前处理站点为: 九丘雨量  当前处理站点为: 京口村雨量  当前处理站点为: 半山村雨量  当前处理站点为: 厚德村雨量  当前处理站点为: 双鲤村雨量  当前处理站点为: 台溪乡雨量  当前处理站点为: 后村雨量  当前处理站点为: 后洋雨量  当前处理站点为: 均中村雨量  当前处理站点为: 埔上镇雨量  当前处理站点为: 夏茂镇雨量  当前处理站点为: 夏阳乡雨量  当前处理站点为: 外洋村雨量  当前处理站点为: 大儒村雨量  当前处理站点为: 大华镇雨量  当前处理站点为: 大口窑雨量  当前处理站点为: 大横镇曲楼甲新农村雨量  当前处理站点为: 天心岛花园雨量  当前处理站点为: 安砂镇雨量  当前处理站点为: 官昌村雨量  当前处理站点为: 富屯溪流域面雨量  当前处理站点为: 小华村雨量  当前处理站点为: 小西门头社区雨量  当前处理站点为: 山下乡雨量  当前处理站点为: 山坊雨量  当前处理站点为: 岭坪雨量  当前处理站点为: 年坂山雨量  当前处理站点为: 广平镇雨量  当前处理站点为: 库区流域面雨量  当前处理站点为: 建溪流域面雨量  当前处理站点为: 文峰村雨量  当前处理站点为: 新桥头雨量  当前处理站点为: 新源村雨量  当前处理站点为: 新阳镇雨量  当前处理站点为: 景山新村雨量  当前处理站点为: 杉坜雨量  当前处理站点为: 李坊村雨量  当前处理站点为: 林后岗雨量  当前处理站点为: 柯坑村雨量  当前处理站点为: 桐木村雨量  当前处理站点为: 桥下村雨量  当前处理站点为: 桥南村雨量  当前处理站点为: 梅仙镇雨量  当前处理站点为: 梅园小区雨量  当前处理站点为: 梅山镇雨量  当前处理站点为: 梅树湾新村雨量  当前处理站点为: 梅溪村雨量  当前处理站点为: 梓溪村雨量  当前处理站点为: 槐南镇雨量  当前处理站点为: 樟树村雨量  当前处理站点为: 横坑村雨量  当前处理站点为: 横洋雨量  当前处理站点为: 民主村雨量  当前处理站点为: 水东区间流域面雨量  当前处理站点为: 水东坝上雨量  当前处理站点为: 水东面雨量  当前处理站点为: 水南村雨量  当前处理站点为: 水口坝上(左岸)雨量  当前处理站点为: 水口坝上雨量  当前处理站点为: 水口面雨量  当前处理站点为: 永坑村雨量  当前处理站点为: 池潭坝上雨量  当前处理站点为: 汤泉村雨量  当前处理站点为: 沙坝下雨量  当前处理站点为: 沙溪流域面雨量  当前处理站点为: 洽湖村雨量  当前处理站点为: 测试雨量  当前处理站点为: 漈村雨量  当前处理站点为: 白叶山雨量  当前处理站点为: 白源雨量  当前处理站点为: 石塔山雨量  当前处理站点为: 碗厂村雨量  当前处理站点为: 福源小区雨量  当前处理站点为: 福记雨量  当前处理站点为: 端溪村雨量  当前处理站点为: 绿柳村雨量  当前处理站点为: 联合镇雨量  当前处理站点为: 肖坂村雨量  当前处理站点为: 胡坊镇雨量  当前处理站点为: 芦坪雨量  当前处理站点为: 茶窠雨量  当前处理站点为: 莘口镇雨量  当前处理站点为: 街面面雨量  当前处理站点为: 西城镇雨量  当前处理站点为: 西津村雨量  当前处理站点为: 西燕村雨量  当前处理站点为: 西表村雨量  当前处理站点为: 观华园雨量  当前处理站点为: 车洋坂雨量  当前处理站点为: 里坪厂雨量  当前处理站点为: 里洋村雨量  当前处理站点为: 金岭村雨量  当前处理站点为: 雍口实时面雨量  当前处理站点为: 雍口面雨量  当前处理站点为: 雪峰新村雨量  当前处理站点为: 龙口村雨量  "
     ]
    }
   ],
   "source": [
    "df_特征_test = pd.DataFrame(test_date_range, columns=['时间'])\n",
    "df = df_test['雨量水位'].copy()\n",
    "df = df[df['名称'].isin(共有监测站)]\n",
    "for 站点名称, group in df.groupby('名称', group_keys=False) :\n",
    "    print(f\"当前处理站点为: {站点名称}\" , end='  ')  # 输出站点ID\n",
    "\n",
    "    # 按时间排序并设置索引\n",
    "    group = group.sort_values('时间').set_index('时间')\n",
    "\n",
    "    # 用 product 生成所有组合\n",
    "    for stat, window in product(stats, windows):\n",
    "        group[f'{站点名称}_{stat}_{window}'] = group['值'].rolling(window, closed='both').agg(stat)\n",
    "    group = group.drop(columns=['名称', '站点id', '值', '平均值', '最大值', '最大值发生时间', '最小值', '最小值发生时间']).reset_index()\n",
    "    group = group.drop_duplicates(subset='时间', keep='first')\n",
    "    # print(group)\n",
    "    df_特征_test = df_特征_test.merge(group , on='时间' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_特征_train = df_特征_train.fillna(0)\n",
    "df_特征_test = df_特征_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52584, 2497)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_特征_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17544, 2497)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_特征_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(特征_train_dir + '1~36小时滑窗特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_train, file)\n",
    "with open(特征_test_dir + '1~36小时滑窗特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取年月日季节性的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_特征_train = pd.DataFrame(train_date_range, columns=['时间'])\n",
    "\n",
    "df_特征_train['年份'] = df_特征_train['时间'].dt.year\n",
    "df_特征_train['月份'] = df_特征_train['时间'].dt.month\n",
    "df_特征_train['日'] = df_特征_train['时间'].dt.day\n",
    "df_特征_train['小时'] = df_特征_train['时间'].dt.hour\n",
    "df_特征_train['星期几'] = df_特征_train['时间'].dt.dayofweek  # 周一=0，周日=6\n",
    "df_特征_train['季度'] = df_特征_train['时间'].dt.quarter\n",
    "df_特征_train['是否周末'] = df_特征_train['星期几'].isin([5,6]).astype(int)\n",
    "\n",
    "# 自定义水文时期特征\n",
    "df_特征_train['水文时期'] = '正常期'\n",
    "df_特征_train.loc[df_特征_train['月份'].isin([5,6,7]), '水文时期'] = '汛期'  # 汛期\n",
    "df_特征_train.loc[df_特征_train['月份'].isin([10,11,12]), '水文时期'] = '枯水期'  # 枯水期\n",
    "\n",
    "# 定义映射字典\n",
    "season_mapping = {'正常期': 0, '汛期': 1, '枯水期': 2}\n",
    "\n",
    "# 应用映射\n",
    "df_特征_train['水文时期编码'] = df_特征_train['水文时期'].map(season_mapping)\n",
    "\n",
    "# 或使用sklearn的LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_特征_train['水文时期编码'] = le.fit_transform(df_特征_train['水文时期'])\n",
    "\n",
    "df_特征_train = df_特征_train.drop(['水文时期'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_特征_test = pd.DataFrame(test_date_range, columns=['时间'])\n",
    "\n",
    "df_特征_test['年份'] = df_特征_test['时间'].dt.year\n",
    "df_特征_test['月份'] = df_特征_test['时间'].dt.month\n",
    "df_特征_test['日'] = df_特征_test['时间'].dt.day\n",
    "df_特征_test['小时'] = df_特征_test['时间'].dt.hour\n",
    "df_特征_test['星期几'] = df_特征_test['时间'].dt.dayofweek  # 周一=0，周日=6\n",
    "df_特征_test['季度'] = df_特征_test['时间'].dt.quarter\n",
    "df_特征_test['是否周末'] = df_特征_test['星期几'].isin([5,6]).astype(int)\n",
    "\n",
    "# 自定义水文时期特征\n",
    "df_特征_test['水文时期'] = '正常期'\n",
    "df_特征_test.loc[df_特征_test['月份'].isin([5,6,7]), '水文时期'] = '汛期'  # 汛期\n",
    "df_特征_test.loc[df_特征_test['月份'].isin([10,11,12]), '水文时期'] = '枯水期'  # 枯水期\n",
    "\n",
    "# 定义映射字典\n",
    "season_mapping = {'正常期': 0, '汛期': 1, '枯水期': 2}\n",
    "\n",
    "# 应用映射\n",
    "df_特征_test['水文时期编码'] = df_特征_test['水文时期'].map(season_mapping)\n",
    "\n",
    "# 或使用sklearn的LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_特征_test['水文时期编码'] = le.fit_transform(df_特征_test['水文时期'])\n",
    "\n",
    "df_特征_test = df_特征_test.drop(['水文时期'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(特征_train_dir + '年月日季节' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_train, file)\n",
    "with open(特征_test_dir + '年月日季节' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 广东哥特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_特征_train = pd.DataFrame(train_date_range, columns=['时间'])\n",
    "df = df_train['雨量水位'].copy()\n",
    "# 按时间分组统计\n",
    "time_group = df.groupby('时间')['值'].agg([\n",
    "    ('v_sum', 'sum'),\n",
    "    ('v_mean', 'mean'),\n",
    "    ('v_std', 'std'),\n",
    "    ('v_max', 'max'),\n",
    "    ('v_min', 'min'),\n",
    "    ('v_skew', 'skew')\n",
    "]).reset_index()\n",
    "\n",
    "# 生成差分特征\n",
    "time_group['v_sum_diff'] = time_group['v_sum'].diff()\n",
    "time_group['v_mean_diff'] = time_group['v_mean'].diff()\n",
    "\n",
    "# 生成滚动窗口特征（示例：8~720小时窗口，步长8）\n",
    "time_group = time_group.sort_values('时间')  # 确保时间有序\n",
    "for w in range(8, 720+8, 8):\n",
    "    time_group[f'v_mean_roll_{w}'] = time_group['v_mean'].rolling(\n",
    "        window=w, \n",
    "        min_periods=1\n",
    "    ).mean()\n",
    "df_特征_train = df_特征_train.merge(time_group , on='时间' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_特征_test = pd.DataFrame(test_date_range, columns=['时间'])\n",
    "df = df_test['雨量水位'].copy()\n",
    "# 按时间分组统计\n",
    "time_group = df.groupby('时间')['值'].agg([\n",
    "    ('v_sum', 'sum'),\n",
    "    ('v_mean', 'mean'),\n",
    "    ('v_std', 'std'),\n",
    "    ('v_max', 'max'),\n",
    "    ('v_min', 'min'),\n",
    "    ('v_skew', 'skew')\n",
    "]).reset_index()\n",
    "\n",
    "# 生成差分特征\n",
    "time_group['v_sum_diff'] = time_group['v_sum'].diff()\n",
    "time_group['v_mean_diff'] = time_group['v_mean'].diff()\n",
    "\n",
    "# 生成滚动窗口特征（示例：8~720小时窗口，步长8）\n",
    "time_group = time_group.sort_values('时间')  # 确保时间有序\n",
    "for w in range(8, 720+8, 8):\n",
    "    time_group[f'v_mean_roll_{w}'] = time_group['v_mean'].rolling(\n",
    "        window=w, \n",
    "        min_periods=1\n",
    "    ).mean()\n",
    "df_特征_test = df_特征_test.merge(time_group , on='时间' , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(特征_train_dir + '广东哥特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_train, file)\n",
    "with open(特征_test_dir + '广东哥特征' + '.pkl' , \"wb\") as file:\n",
    "    pickle.dump(df_特征_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间\n",
      "v_sum\n",
      "v_mean\n",
      "v_std\n",
      "v_max\n",
      "v_min\n",
      "v_skew\n",
      "v_sum_diff\n",
      "v_mean_diff\n",
      "v_mean_roll_8\n",
      "v_mean_roll_16\n",
      "v_mean_roll_24\n",
      "v_mean_roll_32\n",
      "v_mean_roll_40\n",
      "v_mean_roll_48\n",
      "v_mean_roll_56\n",
      "v_mean_roll_64\n",
      "v_mean_roll_72\n",
      "v_mean_roll_80\n",
      "v_mean_roll_88\n",
      "v_mean_roll_96\n",
      "v_mean_roll_104\n",
      "v_mean_roll_112\n",
      "v_mean_roll_120\n",
      "v_mean_roll_128\n",
      "v_mean_roll_136\n",
      "v_mean_roll_144\n",
      "v_mean_roll_152\n",
      "v_mean_roll_160\n",
      "v_mean_roll_168\n",
      "v_mean_roll_176\n",
      "v_mean_roll_184\n",
      "v_mean_roll_192\n",
      "v_mean_roll_200\n",
      "v_mean_roll_208\n",
      "v_mean_roll_216\n",
      "v_mean_roll_224\n",
      "v_mean_roll_232\n",
      "v_mean_roll_240\n",
      "v_mean_roll_248\n",
      "v_mean_roll_256\n",
      "v_mean_roll_264\n",
      "v_mean_roll_272\n",
      "v_mean_roll_280\n",
      "v_mean_roll_288\n",
      "v_mean_roll_296\n",
      "v_mean_roll_304\n",
      "v_mean_roll_312\n",
      "v_mean_roll_320\n",
      "v_mean_roll_328\n",
      "v_mean_roll_336\n",
      "v_mean_roll_344\n",
      "v_mean_roll_352\n",
      "v_mean_roll_360\n",
      "v_mean_roll_368\n",
      "v_mean_roll_376\n",
      "v_mean_roll_384\n",
      "v_mean_roll_392\n",
      "v_mean_roll_400\n",
      "v_mean_roll_408\n",
      "v_mean_roll_416\n",
      "v_mean_roll_424\n",
      "v_mean_roll_432\n",
      "v_mean_roll_440\n",
      "v_mean_roll_448\n",
      "v_mean_roll_456\n",
      "v_mean_roll_464\n",
      "v_mean_roll_472\n",
      "v_mean_roll_480\n",
      "v_mean_roll_488\n",
      "v_mean_roll_496\n",
      "v_mean_roll_504\n",
      "v_mean_roll_512\n",
      "v_mean_roll_520\n",
      "v_mean_roll_528\n",
      "v_mean_roll_536\n",
      "v_mean_roll_544\n",
      "v_mean_roll_552\n",
      "v_mean_roll_560\n",
      "v_mean_roll_568\n",
      "v_mean_roll_576\n",
      "v_mean_roll_584\n",
      "v_mean_roll_592\n",
      "v_mean_roll_600\n",
      "v_mean_roll_608\n",
      "v_mean_roll_616\n",
      "v_mean_roll_624\n",
      "v_mean_roll_632\n",
      "v_mean_roll_640\n",
      "v_mean_roll_648\n",
      "v_mean_roll_656\n",
      "v_mean_roll_664\n",
      "v_mean_roll_672\n",
      "v_mean_roll_680\n",
      "v_mean_roll_688\n",
      "v_mean_roll_696\n",
      "v_mean_roll_704\n",
      "v_mean_roll_712\n",
      "v_mean_roll_720\n"
     ]
    }
   ],
   "source": [
    "for i in df_特征_train.columns :\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
